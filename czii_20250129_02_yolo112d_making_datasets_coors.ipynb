{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb473bfa-fa91-4d32-b8fd-0adfb4477a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zarr\n",
    "from tqdm import tqdm\n",
    "import glob, os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e7f3ae-f70d-458a-b09b-60abaa1ba8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/max1024/Extreme SSD1/Kaggle/czii-cryo-et-object-identification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4edb414-d1de-4231-acbd-1182503b1230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'TS_5_4',\n",
       " 1: 'TS_69_2',\n",
       " 2: 'TS_6_4',\n",
       " 3: 'TS_6_6',\n",
       " 4: 'TS_73_6',\n",
       " 5: 'TS_86_3',\n",
       " 6: 'TS_99_9'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = sorted(glob.glob(path + 'train/overlay/ExperimentRuns/*'))\n",
    "runs = [os.path.basename(x) for x in runs]\n",
    "i2r_dict = {i:r for i, r in zip(range(len(runs)), runs)}\n",
    "r2t_dict = {r:i for i, r in zip(range(len(runs)), runs)}\n",
    "i2r_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da8d8859-d534-44e5-b9e4-0a32e1fb4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_8bit(x):\n",
    "    lower, upper = np.percentile(x, (0.5, 99.5))\n",
    "    x = np.clip(x, lower, upper)\n",
    "    x = (x - x.min()) / (x.max() - x.min() + 1e-12) * 255\n",
    "    return x.round().astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a828654c-ffe4-4f00-9b39-1c3d5070e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2i_dict = {\n",
    "        'apo-ferritin': 0,\n",
    "        'beta-amylase': 1,\n",
    "        'beta-galactosidase': 2,\n",
    "        'ribosome': 3,\n",
    "        'thyroglobulin': 4,\n",
    "        'virus-like-particle': 5\n",
    "    }\n",
    "\n",
    "i2p = {v:k for k, v in p2i_dict.items()}\n",
    "\n",
    "particle_radius = {\n",
    "        'apo-ferritin': 60,\n",
    "        'beta-amylase': 65,\n",
    "        'beta-galactosidase': 90,\n",
    "        'ribosome': 150,\n",
    "        'thyroglobulin': 130,\n",
    "        'virus-like-particle': 135,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a66b60-fc81-4dcd-8128-d69c4abb0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_names = ['apo-ferritin', 'beta-amylase', 'beta-galactosidase', 'ribosome', 'thyroglobulin', 'virus-like-particle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f23b46-765f-4792-bdf0-3ed72643f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_annotate_yolo(run_name, is_train_path=True):\n",
    "    # to split validation\n",
    "    is_train_path = 'train' if is_train_path else 'val'\n",
    "\n",
    "    # read a volume\n",
    "    vol = zarr.open(path + f'train/static/ExperimentRuns/{run_name}/VoxelSpacing10.000/denoised.zarr', mode='r') #bug fixed. Thanks to @pratyushh\n",
    "    # use largest images\n",
    "    vol = vol[0]\n",
    "    # normalize [0, 255]\n",
    "    vol2 = convert_to_8bit(vol)\n",
    "    \n",
    "    n_imgs = vol2.shape[0]\n",
    "    # process each slices\n",
    "    for j in range(n_imgs):\n",
    "        newvol = vol2[j]\n",
    "        newvolf = np.stack([newvol]*3, axis=-1)\n",
    "        # YOLO requires image_size is multiple of 32\n",
    "        newvolf = cv2.resize(newvolf, (640,640))\n",
    "        # save as 1 slice\n",
    "        cv2.imwrite(path + f'output/images/{is_train_path}/{run_name}_{j*10}.png', newvolf)\n",
    "        # make txt file for annotation\n",
    "        with open(path + f'output/labels/{is_train_path}/{run_name}_{j*10}.txt', 'w'):\n",
    "            pass # make empty file\n",
    "            \n",
    "    # process each paticle types\n",
    "    for p, particle in enumerate(tqdm(particle_names)):\n",
    "        # we do not have to detect beta-amylase which weight is 0\n",
    "        if particle==\"beta-amylase\":\n",
    "            continue\n",
    "        json_each_paticle = path + f\"train/overlay/ExperimentRuns/{run_name}/Picks/{particle}.json\"\n",
    "        df = pd.read_json(json_each_paticle) \n",
    "        # pick each coordinate of particles\n",
    "        for axis in \"x\", \"y\", \"z\":\n",
    "            df[axis] = df.points.apply(lambda x: x[\"location\"][axis])\n",
    "\n",
    "        \n",
    "        radius = particle_radius[particle]\n",
    "        for i, row in df.iterrows():\n",
    "            # The radius from the center of the particle is used to determine the slices present.\n",
    "            start_z = np.round(row['z'] - radius).astype(np.int32)\n",
    "            start_z = max(0, start_z//10) # 10 means pixelspacing\n",
    "            end_z = np.round(row['z'] + radius).astype(np.int32)\n",
    "            end_z = min(n_imgs, end_z//10) # 10 means pixelspacing\n",
    "            \n",
    "            for j in range(start_z+1, end_z+1-1, 1):\n",
    "                # white the results of annotation\n",
    "                with open(path + f'output/labels/{is_train_path}/{run_name}_{j*10}.txt', 'a') as f:\n",
    "                    f.write(f'{p2i_dict[particle]} {row[\"x\"]/10.012444537618887/vol2.shape[1]} {row[\"y\"]/10.012444196428572/vol2.shape[2]} {radius/10/vol2.shape[1]*2} {radius/10/vol2.shape[2]*2} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea334a8b-0b47-41b9-9788-fc6abb8b467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(path + \"output/images/train\", exist_ok=True)\n",
    "os.makedirs(path + \"output/images/val\", exist_ok=True)\n",
    "os.makedirs(path + \"output/labels/val\", exist_ok=True)\n",
    "os.makedirs(path + \"output/labels/train\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bdf4661-48b7-4a82-aec5-eef4b5424596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 61.74it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 59.98it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 45.31it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 64.75it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 46.11it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 40.27it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:00<00:00, 43.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# use TS_5_4 as validation\n",
    "for i, r in enumerate(runs):\n",
    "    make_annotate_yolo(r, is_train_path=False if i==0 else True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2927583b-b1dd-4929-bbc7-a5eb2c68fa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/max1024/Extreme SSD1/Kaggle/czii-cryo-et-object-identification/output/datasets/czii_det2d/labels/val'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "os.makedirs(path + 'output/datasets/czii_det2d', exist_ok=True)\n",
    "shutil.move(path + 'output/images/train', path + 'output/datasets/czii_det2d/images/train')\n",
    "shutil.move(path + 'output/images/val', path + 'output/datasets/czii_det2d/images')\n",
    "shutil.move(path + 'output/labels/train', path + 'output/datasets/czii_det2d/labels/train')\n",
    "shutil.move(path + 'output/labels/val', path + 'output/datasets/czii_det2d/labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57600d4-49e3-450a-82d2-11daf27ca5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting czii_conf.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile czii_conf.yaml\n",
    "\n",
    "path: /media/max1024/Extreme SSD1/Kaggle/czii-cryo-et-object-identification/output/datasets/czii_det2d # dataset root dir\n",
    "train: images/train # train images (relative to 'path') \n",
    "val: images/val # val images (relative to 'path') \n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: apo-ferritin\n",
    "  1: beta-amylase\n",
    "  2: beta-galactosidase\n",
    "  3: ribosome\n",
    "  4: thyroglobulin\n",
    "  5: virus-like-particle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8803f-9ec8-4ea1-82cd-5cb035a5398f",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. https://www.kaggle.com/code/itsuki9180/czii-making-datasets-for-yolo/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb02fc-fdf8-4648-9643-7dc015234631",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
